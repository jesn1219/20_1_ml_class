{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Writer : Jesoon Kang, Chung-Ang University\n",
    "* last-modified date : June 4, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import math\n",
    "from IPython.display import display, Math, Latex\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "file_data   = \"mnist.csv\"\n",
    "handle_file = open(file_data, \"r\")\n",
    "data        = handle_file.readlines()\n",
    "handle_file.close()\n",
    "\n",
    "size_row    = 28    # height of the image\n",
    "size_col    = 28    # width of the image\n",
    "\n",
    "num_image   = len(data)\n",
    "count       = 0     # count for the number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2060 SUPER\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "### Setting up Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Below codes activates when want to use cpu\n",
    "#device = torch.device('cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# normalize the values of the input data to be [0, 1]\n",
    "#\n",
    "def normalize(data):\n",
    "\n",
    "    data_normalized = (data - min(data)) / (max(data) - min(data))\n",
    "\n",
    "    return(data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# example of distance function between two vectors x and y\n",
    "#\n",
    "def distance(x, y):\n",
    "\n",
    "    d = (x - y) ** 2\n",
    "    s = np.sum(d)\n",
    "    # r = np.sqrt(s)\n",
    "\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# make a matrix each column of which represents an images in a vector form\n",
    "#\n",
    "list_image  = np.empty((size_row * size_col, num_image), dtype=float)\n",
    "list_label  = np.empty(num_image, dtype=int)\n",
    "\n",
    "for line in data:\n",
    "\n",
    "    line_data   = line.split(',')\n",
    "    label       = line_data[0]\n",
    "    im_vector   = np.asfarray(line_data[1:])\n",
    "    im_vector   = normalize(im_vector)\n",
    "\n",
    "    list_label[count]       = label\n",
    "    list_image[:, count]    = im_vector\n",
    "\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(z):\n",
    "    sig_value =  1.0 / (1.0 + np.exp(-z))\n",
    "    return sig_value * (1 - sig_value)\n",
    "\n",
    "# Return derivative of in\n",
    "def sig_grad(z) :\n",
    "    return z * (1-z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(list_image,list_label) :\n",
    "    f1 = plt.figure(1)\n",
    "    \n",
    "    for i in range(10):\n",
    "        label       = list_label[i]\n",
    "        im_vector   = list_image[:, i]\n",
    "        im_matrix   = im_vector.reshape((size_row, size_col))\n",
    "\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.title(label)\n",
    "        plt.imshow(im_matrix, cmap='Greys', interpolation='None')\n",
    "\n",
    "        frame   = plt.gca()\n",
    "        frame.axes.get_xaxis().set_visible(False)\n",
    "        frame.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_running_time(start_time) :\n",
    "    running_time = datetime.datetime.now() - start_time\n",
    "    running_time = running_time.seconds\n",
    "    hours, remainder = divmod(running_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return hours, minutes, seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_image = list_image[:, :1000]\n",
    "train_label = list_label[:1000]\n",
    "test_image = list_image[:,1000:]\n",
    "test_label = list_label[1000:]\n",
    "\n",
    "train_label_vec = np.zeros((10, train_label.shape[0]))\n",
    "test_label_vec = np.zeros((10, test_label.shape[0]))\n",
    "for i, val in enumerate(train_label):\n",
    "    train_label_vec[val, i] = 1.0\n",
    "for i, val in enumerate(test_label):\n",
    "    test_label_vec[val, i] = 1.0\n",
    "\n",
    "    \n",
    "train_input_with_bias = np.ones((train_image.shape[0]+1, train_image.shape[1])) # add bia\n",
    "train_input_with_bias[1:, :] = train_image\n",
    "test_input_with_bias = np.ones((test_image.shape[0]+1, test_image.shape[1])) # add bia\n",
    "test_input_with_bias[1:, :] = test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_with_bias = torch.DoubleTensor(train_input_with_bias).to(device)\n",
    "test_input_with_bias = torch.DoubleTensor(test_input_with_bias).to(device)\n",
    "train_label_vec = torch.DoubleTensor(train_label_vec).to(device)\n",
    "test_label_vec = torch.DoubleTensor(test_label_vec).to(device)\n",
    "train_label = torch.DoubleTensor(train_label).to(device)\n",
    "test_label = torch.DoubleTensor(test_label).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML :\n",
    "    def __init__(self,layer_info = [196,49,10],lr = 1e-3,weight_decay= 1e-4,loss_conv = 1e-6,monitoring_epoch = 0) :\n",
    "        print('-'*20,\"ML START\", '-'*20)\n",
    "        \n",
    "        \n",
    "        print(\"lr : {}, weight_decay : {}, loss_conv : {}, thetas : {}\".format(lr, weight_decay, loss_conv, layer_info))\n",
    "        self.list_layer_info = layer_info\n",
    "        self.init_thetas()\n",
    "        \n",
    "        # Get number of thetas(total)\n",
    "        self.th_num = 0\n",
    "        for th in self.list_theta :\n",
    "            self.th_num += th.view(-1).shape[0]\n",
    "        \n",
    "        \n",
    "        self.monitoring_epoch = monitoring_epoch\n",
    "        self.num_hidden_layer = len(self.list_theta)-1\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.loss_conv = loss_conv\n",
    "        self.epoch = 0\n",
    "        self.list_epoch = []\n",
    "        self.list_loss_train = []\n",
    "        self.list_loss_test = []\n",
    "        self.list_acc_train = []\n",
    "        self.list_acc_test = []\n",
    "        self.list_y = []\n",
    "        self.list_a = []\n",
    "        self.result_train = {}\n",
    "        self.result_test = {}\n",
    "        self.start_time = datetime.datetime.now()\n",
    "        self.exit_count = 0\n",
    "        self.list_dL = []\n",
    "        self.list_grad = []\n",
    "        self.exit_count = 0\n",
    "        self.train()\n",
    "\n",
    "    def get_mean_theta_square(self,list_theta) :\n",
    "        sum_th = 0\n",
    "        th_num = 0\n",
    "        for th in list_theta :\n",
    "            sum_th += torch.sum(th**2)\n",
    "            th_num += th.view(-1).shape[0]\n",
    "        return sum_th/self.th_num\n",
    "    \n",
    "    \n",
    "    def init_thetas(self) :\n",
    "        self.list_theta = []\n",
    "        list_d = [784]\n",
    "        for d in self.list_layer_info :\n",
    "            th = torch.randn((d,list_d[-1]+1),dtype=torch.double).to(device)\n",
    "            self.list_theta.append(th)\n",
    "            list_d.append(d)\n",
    "        \n",
    "    def monitoring(self) :\n",
    "        if self.monitoring_epoch != 0 :\n",
    "            if self.epoch % self.monitoring_epoch == 0 :\n",
    "                running_time = get_running_time(self.start_time)\n",
    "                print(\"Train Acc : {:.3f}, Loss : {:.8f} | epoch : {}, time : {:02d}:{:02d}:{:02d}\\nTest  Acc : {:.3f}, Loss : {:.8f}\".\\\n",
    "                      format(self.list_acc_train[-1],self.list_loss_train[-1],self.epoch,running_time[0],running_time[1],running_time[2],self.list_acc_test[-1],self.list_loss_test[-1]))\n",
    "        \n",
    "    def train(self) :\n",
    "        while (True) :\n",
    "            self.forward_propagation_train()\n",
    "            self.set_gradient_decent()\n",
    "            self.forward_propagation_test()\n",
    "            self.update_weights()\n",
    "            self.monitoring()\n",
    "            \n",
    "            if self.check_terminate() :\n",
    "                self.terminate()\n",
    "                break\n",
    "        \n",
    "\n",
    "    def check_terminate(self) :\n",
    "        if self.epoch > 5 :\n",
    "            loss_gap = abs(self.list_loss_train[-1] - self.list_loss_train[-2])\n",
    "            if loss_gap < self.loss_conv :\n",
    "                self.exit_count += 1\n",
    "            else :\n",
    "                self.exit_count = 0\n",
    "            if self.exit_count > 4 :\n",
    "                return True\n",
    "\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def terminate(self) :\n",
    "        # Save result.\n",
    "        self.result_train[\"epoch\"] = self.list_epoch\n",
    "        self.result_train[\"loss\"] = self.list_loss_train\n",
    "        self.result_train[\"acc\"] = self.list_acc_train\n",
    "        self.result_train[\"theta\"] = self.list_theta\n",
    "\n",
    "        self.result_test[\"epoch\"] = self.list_epoch\n",
    "        self.result_test[\"loss\"] = self.list_loss_test\n",
    "        self.result_test[\"acc\"] = self.list_acc_test\n",
    "\n",
    "        # Save Sample images\n",
    "        list_correct_image = []\n",
    "        list_correct_label = []\n",
    "        list_incorrect_image = []\n",
    "        list_incorrect_label = []\n",
    "        num_correct=0\n",
    "        num_incorrect=0\n",
    "\n",
    "        for i, correct in enumerate(test_label == self.predict_test) :\n",
    "            if (correct) :\n",
    "                if num_correct < 10 :\n",
    "                    list_correct_image.append(test_image[:,i])\n",
    "                    list_correct_label.append(int(test_label[i].item()))\n",
    "                    num_correct += 1\n",
    "            else :\n",
    "                if num_incorrect < 10 :\n",
    "                    list_incorrect_image.append(test_image[:,i])\n",
    "                    list_incorrect_label.append(int(self.predict_test[i].item()))\n",
    "                    num_incorrect += 1\n",
    "            if num_correct >= 10 and num_incorrect >= 10 :\n",
    "                break\n",
    "        self.result_test[\"correct_image\"] = list_correct_image\n",
    "        self.result_test[\"correct_label\"] = list_correct_label\n",
    "        self.result_test[\"incorrect_image\"] = list_incorrect_image\n",
    "        self.result_test[\"incorrect_label\"] = list_incorrect_label\n",
    "\n",
    "        print(\"Loss is converged. epoch {}\".format(self.epoch))\n",
    "        print(\"Training Process Ended\")\n",
    "        return True\n",
    "        \n",
    "    \n",
    "    def forward_propagation_train(self) :\n",
    "        self.epoch += 1\n",
    "        self.list_epoch.append(self.epoch)\n",
    "        self.list_y = []\n",
    "        self.list_a = []\n",
    "        self.list_a_bias = [train_input_with_bias]\n",
    "        for idx, th in enumerate(self.list_theta) :    \n",
    "            y_tmp = torch.mm(th,self.list_a_bias[-1])\n",
    "            self.list_y.append(y_tmp)\n",
    "            a_tmp = 1 / (1 + torch.exp(-y_tmp))\n",
    "            self.list_a.append(a_tmp)\n",
    "            a_bias_tmp = torch.ones((a_tmp.shape[0] + 1, a_tmp.shape[1]), dtype=torch.double).to(device)\n",
    "            a_bias_tmp[1:, :] = a_tmp\n",
    "            self.list_a_bias.append(a_bias_tmp)\n",
    "        self.list_a_bias.pop()\n",
    "        \n",
    "        h = self.list_a[-1]\n",
    "        loss_train = torch.sum(-train_label_vec * (torch.log(h)) - (1 - train_label_vec)* torch.log(1 - h)) / len(h.T) + self.weight_decay*0.5*self.get_mean_theta_square(self.list_theta)\n",
    "        self.list_loss_train.append(loss_train)\n",
    "        # Calculate Acc\n",
    "        self.predict_train = torch.argmax(h, axis = 0)\n",
    "        self.correct_train = torch.sum(train_label == self.predict_train, axis = 0)\n",
    "        acc_train = self.correct_train.item()/train_label.shape[0]\n",
    "        self.list_acc_train.append(acc_train)\n",
    "        \n",
    "    def forward_propagation_test(self) :\n",
    "        self.list_y = []\n",
    "        self.list_a = []\n",
    "        self.list_a_bias = [test_input_with_bias]\n",
    "        for idx, th in enumerate(self.list_theta) :\n",
    "           \n",
    "            y_tmp = torch.mm(th,self.list_a_bias[-1])\n",
    "            self.list_y.append(y_tmp)\n",
    "            a_tmp = 1 / (1 + torch.exp(-y_tmp))\n",
    "            self.list_a.append(a_tmp)\n",
    "            a_bias_tmp = torch.ones((a_tmp.shape[0] + 1, a_tmp.shape[1]), dtype=torch.double).to(device)\n",
    "            a_bias_tmp[1:, :] = a_tmp\n",
    "            self.list_a_bias.append(a_bias_tmp)\n",
    "        self.list_a_bias.pop()\n",
    "        \n",
    "        h = self.list_a[-1]\n",
    "        loss_test = torch.sum(-test_label_vec * (torch.log(h)) - (1 - test_label_vec)* torch.log(1 - h)) / len(h.T) + self.weight_decay*0.5*self.get_mean_theta_square(self.list_theta)\n",
    "        self.list_loss_test.append(loss_test)\n",
    "\n",
    "\n",
    "        # Calculate Acc\n",
    "        self.predict_test = torch.argmax(h, axis = 0)\n",
    "        self.correct_test = torch.sum(test_label == self.predict_test, axis = 0)\n",
    "        acc_test = self.correct_test.item()/test_label.shape[0]\n",
    "        self.list_acc_test.append(acc_test)\n",
    "        \n",
    "    def set_gradient_decent (self) :\n",
    "         # Back propagation\n",
    "        self.list_dL = []\n",
    "        self.list_grad = []\n",
    "        \n",
    "        self.list_dL.append(self.list_a[-1]-train_label_vec)\n",
    "        grad = torch.mm(self.list_dL[-1],self.list_a_bias[-1].T) + self.weight_decay*0.5*self.list_theta[-1]#/self.th_num\n",
    "        \n",
    "        self.list_grad.append(torch.mm(self.list_dL[-1],self.list_a_bias[-1].T))\n",
    "        idx = 0\n",
    "        # Calculate gradient decent in order from back-end\n",
    "        for i in range(0,self.num_hidden_layer) :\n",
    "            idx += 1\n",
    "            dL_dy = torch.mm(self.list_theta[-idx].T,self.list_dL[-1]) * sig_grad(self.list_a_bias[-idx])\n",
    "            dL_dy = dL_dy[1:, :]\n",
    "            self.list_dL.append(dL_dy)\n",
    "            #\n",
    "            # \n",
    "            #  weight decay / n * theta\n",
    "            #\n",
    "            \n",
    "            grad = torch.mm(dL_dy, self.list_a_bias[-(idx+1)].T)\n",
    "            grad_2 = self.weight_decay*self.list_theta[-(idx+1)]#/self.th_num\n",
    "            grad = grad + grad_2\n",
    "            self.list_grad.append(grad)\n",
    "        self.list_grad.reverse()\n",
    "        \n",
    "        # There needs more \n",
    "    def update_weights(self) :\n",
    "        for th, grad in zip(self.list_theta,self.list_grad) :\n",
    "            th -= self.lr * (grad)\n",
    "            \n",
    "    \n",
    "    def show_correct_example(self) :\n",
    "\n",
    "        list_label = self.result_test[\"correct_label\"]\n",
    "        list_image = np.array(self.result_test[\"correct_image\"]).T\n",
    "        f1 = plt.figure(1)\n",
    "\n",
    "        for i in range(10):\n",
    "            label       = list_label[i]\n",
    "            im_vector   = list_image[:, i]\n",
    "            im_matrix   = im_vector.reshape((size_row, size_col))\n",
    "\n",
    "            plt.subplot(2, 5, i+1)\n",
    "            plt.title(label)\n",
    "            plt.imshow(im_matrix, cmap='Greys', interpolation='None')\n",
    "\n",
    "            frame   = plt.gca()\n",
    "            frame.axes.get_xaxis().set_visible(False)\n",
    "            frame.axes.get_yaxis().set_visible(False)\n",
    "        plt.show()    \n",
    "\n",
    "    def show_incorrect_example(self) :\n",
    "\n",
    "        list_label = self.result_test[\"incorrect_label\"]\n",
    "        list_image = np.array(self.result_test[\"incorrect_image\"]).T\n",
    "        f1 = plt.figure(1)\n",
    "\n",
    "        for i in range(10):\n",
    "            label       = list_label[i]\n",
    "            im_vector   = list_image[:, i]\n",
    "            im_matrix   = im_vector.reshape((size_row, size_col))\n",
    "\n",
    "            plt.subplot(2, 5, i+1)\n",
    "            plt.title(label)\n",
    "            plt.imshow(im_matrix, cmap='Greys', interpolation='None')\n",
    "\n",
    "            frame   = plt.gca()\n",
    "            frame.axes.get_xaxis().set_visible(False)\n",
    "            frame.axes.get_yaxis().set_visible(False)\n",
    "        plt.show()    \n",
    "    def show_loss_curve(self) :\n",
    "        plt.title(\"Loss curve\")\n",
    "        plot_1, = plt.plot(self.result_train[\"epoch\"],self.result_train[\"loss\"], color='b',linewidth=2,alpha=0.8)\n",
    "        plot_2, = plt.plot(self.result_test[\"epoch\"],self.result_test[\"loss\"], color='r',linewidth=2,alpha=0.8)\n",
    "        plt.legend([plot_1,plot_2],[\"Training\",\"Testing\"])\n",
    "\n",
    "    def show_acc_curve(self) :\n",
    "        plt.title(\"Accuracy curve\")\n",
    "        plot_1, = plt.plot(self.result_train[\"epoch\"],self.result_train[\"acc\"], color='b',linewidth=2,alpha=0.8)\n",
    "        plot_2, = plt.plot(self.result_test[\"epoch\"],self.result_test[\"acc\"], color='r',linewidth=2,alpha=0.8)\n",
    "        plt.legend([plot_1,plot_2],[\"Training\",\"Testing\"])\n",
    "\n",
    "    def show_final_acc(self) :\n",
    "        print(\"Final Training Acc : {:.3f}%\\nFinal Testing Acc : {:.3f}%\".format(self.result_train[\"acc\"][-1]*100,self.result_test[\"acc\"][-1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-09, thetas : [196, 49, 10]\n",
      "Train Acc : 1.000, Loss : 0.14063381 | epoch : 1000, time : 00:00:27\n",
      "Test  Acc : 0.825, Loss : 1.28453920\n",
      "Train Acc : 1.000, Loss : 0.06733109 | epoch : 2000, time : 00:00:53\n",
      "Test  Acc : 0.858, Loss : 1.06526514\n",
      "Train Acc : 1.000, Loss : 0.04129245 | epoch : 3000, time : 00:01:19\n",
      "Test  Acc : 0.875, Loss : 0.91916893\n",
      "Train Acc : 1.000, Loss : 0.03011440 | epoch : 4000, time : 00:01:45\n",
      "Test  Acc : 0.882, Loss : 0.85717189\n",
      "Train Acc : 1.000, Loss : 0.02495778 | epoch : 5000, time : 00:02:11\n",
      "Test  Acc : 0.883, Loss : 0.85454126\n",
      "Train Acc : 0.116, Loss : 4.36412919 | epoch : 6000, time : 00:02:37\n",
      "Test  Acc : 0.102, Loss : 4.41456931\n",
      "Train Acc : 1.000, Loss : 0.08297750 | epoch : 7000, time : 00:03:03\n",
      "Test  Acc : 0.888, Loss : 0.74024196\n",
      "Train Acc : 1.000, Loss : 0.03415230 | epoch : 8000, time : 00:03:29\n",
      "Test  Acc : 0.888, Loss : 0.77071413\n",
      "Train Acc : 1.000, Loss : 0.02494676 | epoch : 9000, time : 00:03:55\n",
      "Test  Acc : 0.887, Loss : 0.80343904\n",
      "Train Acc : 1.000, Loss : 0.01947680 | epoch : 10000, time : 00:04:21\n",
      "Test  Acc : 0.885, Loss : 0.86265709\n",
      "Train Acc : 1.000, Loss : 0.01750782 | epoch : 11000, time : 00:04:46\n",
      "Test  Acc : 0.885, Loss : 0.91135812\n",
      "Train Acc : 1.000, Loss : 0.01670476 | epoch : 12000, time : 00:05:12\n",
      "Test  Acc : 0.885, Loss : 0.93996499\n",
      "Train Acc : 1.000, Loss : 0.01630546 | epoch : 13000, time : 00:05:38\n",
      "Test  Acc : 0.884, Loss : 0.95607070\n",
      "Train Acc : 1.000, Loss : 0.01597770 | epoch : 14000, time : 00:06:04\n",
      "Test  Acc : 0.884, Loss : 0.96806264\n",
      "Train Acc : 1.000, Loss : 0.01626284 | epoch : 15000, time : 00:06:30\n",
      "Test  Acc : 0.888, Loss : 0.93620824\n",
      "Train Acc : 1.000, Loss : 0.01510578 | epoch : 16000, time : 00:06:56\n",
      "Test  Acc : 0.885, Loss : 0.95752348\n",
      "Train Acc : 1.000, Loss : 0.01570315 | epoch : 17000, time : 00:07:22\n",
      "Test  Acc : 0.885, Loss : 0.95927104\n",
      "Loss is converged. epoch 17180\n",
      "Training Process Ended\n"
     ]
    }
   ],
   "source": [
    "ml = ML([196,49,10],lr= 1e-3,loss_conv = 1e-9,weight_decay=4e-1,monitoring_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- ML START --------------------\n",
      "lr : 0.0001, weight_decay : 0.1, loss_conv : 1e-09, thetas : [196, 49, 10]\n",
      "Train Acc : 0.906, Loss : 0.89375917 | epoch : 1000, time : 00:00:26\n",
      "Test  Acc : 0.682, Loss : 1.77124851\n",
      "Train Acc : 0.973, Loss : 0.47485485 | epoch : 2000, time : 00:00:52\n",
      "Test  Acc : 0.733, Loss : 1.56626310\n",
      "Train Acc : 0.995, Loss : 0.29878660 | epoch : 3000, time : 00:01:18\n",
      "Test  Acc : 0.757, Loss : 1.49442605\n",
      "Train Acc : 0.997, Loss : 0.21215844 | epoch : 4000, time : 00:01:44\n",
      "Test  Acc : 0.770, Loss : 1.46646022\n",
      "Train Acc : 1.000, Loss : 0.16373768 | epoch : 5000, time : 00:02:10\n",
      "Test  Acc : 0.777, Loss : 1.45735795\n",
      "Train Acc : 1.000, Loss : 0.13428973 | epoch : 6000, time : 00:02:36\n",
      "Test  Acc : 0.782, Loss : 1.45527797\n",
      "Train Acc : 1.000, Loss : 0.11540523 | epoch : 7000, time : 00:03:02\n",
      "Test  Acc : 0.784, Loss : 1.45520443\n",
      "Train Acc : 1.000, Loss : 0.10204796 | epoch : 8000, time : 00:03:28\n",
      "Test  Acc : 0.787, Loss : 1.45533579\n",
      "Train Acc : 1.000, Loss : 0.09221416 | epoch : 9000, time : 00:03:54\n",
      "Test  Acc : 0.790, Loss : 1.45529437\n",
      "Train Acc : 1.000, Loss : 0.08472274 | epoch : 10000, time : 00:04:20\n",
      "Test  Acc : 0.792, Loss : 1.45524344\n",
      "Train Acc : 1.000, Loss : 0.07876253 | epoch : 11000, time : 00:04:46\n",
      "Test  Acc : 0.795, Loss : 1.45515284\n",
      "Train Acc : 1.000, Loss : 0.07387513 | epoch : 12000, time : 00:05:12\n",
      "Test  Acc : 0.798, Loss : 1.45511736\n",
      "Train Acc : 1.000, Loss : 0.06978196 | epoch : 13000, time : 00:05:38\n",
      "Test  Acc : 0.800, Loss : 1.45510120\n",
      "Train Acc : 1.000, Loss : 0.06628378 | epoch : 14000, time : 00:06:07\n",
      "Test  Acc : 0.802, Loss : 1.45488485\n",
      "Train Acc : 1.000, Loss : 0.06326182 | epoch : 15000, time : 00:06:34\n",
      "Test  Acc : 0.802, Loss : 1.45416860\n",
      "Train Acc : 1.000, Loss : 0.06061888 | epoch : 16000, time : 00:07:00\n",
      "Test  Acc : 0.803, Loss : 1.45297012\n",
      "Train Acc : 1.000, Loss : 0.05827732 | epoch : 17000, time : 00:07:26\n",
      "Test  Acc : 0.805, Loss : 1.45140739\n",
      "Train Acc : 1.000, Loss : 0.05617697 | epoch : 18000, time : 00:07:52\n",
      "Test  Acc : 0.806, Loss : 1.44955946\n",
      "Train Acc : 1.000, Loss : 0.05427210 | epoch : 19000, time : 00:08:18\n",
      "Test  Acc : 0.807, Loss : 1.44748064\n",
      "Train Acc : 1.000, Loss : 0.05252875 | epoch : 20000, time : 00:08:44\n",
      "Test  Acc : 0.809, Loss : 1.44520412\n",
      "Train Acc : 1.000, Loss : 0.05092125 | epoch : 21000, time : 00:09:11\n",
      "Test  Acc : 0.810, Loss : 1.44274300\n",
      "Train Acc : 1.000, Loss : 0.04942957 | epoch : 22000, time : 00:09:37\n",
      "Test  Acc : 0.812, Loss : 1.44009854\n",
      "Train Acc : 1.000, Loss : 0.04803771 | epoch : 23000, time : 00:10:03\n",
      "Test  Acc : 0.812, Loss : 1.43727166\n",
      "Train Acc : 1.000, Loss : 0.04673267 | epoch : 24000, time : 00:10:30\n",
      "Test  Acc : 0.814, Loss : 1.43426940\n",
      "Train Acc : 1.000, Loss : 0.04550370 | epoch : 25000, time : 00:10:56\n",
      "Test  Acc : 0.816, Loss : 1.43110551\n",
      "Train Acc : 1.000, Loss : 0.04434166 | epoch : 26000, time : 00:11:22\n",
      "Test  Acc : 0.816, Loss : 1.42779822\n",
      "Train Acc : 1.000, Loss : 0.04323867 | epoch : 27000, time : 00:11:48\n",
      "Test  Acc : 0.816, Loss : 1.42436777\n",
      "Train Acc : 1.000, Loss : 0.04218785 | epoch : 28000, time : 00:12:14\n",
      "Test  Acc : 0.817, Loss : 1.42083342\n",
      "Train Acc : 1.000, Loss : 0.04118329 | epoch : 29000, time : 00:12:40\n",
      "Test  Acc : 0.818, Loss : 1.41720824\n",
      "Train Acc : 1.000, Loss : 0.04022041 | epoch : 30000, time : 00:13:06\n",
      "Test  Acc : 0.820, Loss : 1.41349026\n",
      "Train Acc : 1.000, Loss : 0.03929640 | epoch : 31000, time : 00:13:32\n",
      "Test  Acc : 0.821, Loss : 1.40965789\n",
      "Train Acc : 1.000, Loss : 0.03840988 | epoch : 32000, time : 00:13:58\n",
      "Test  Acc : 0.822, Loss : 1.40568441\n",
      "Train Acc : 1.000, Loss : 0.03755964 | epoch : 33000, time : 00:14:24\n",
      "Test  Acc : 0.822, Loss : 1.40156130\n",
      "Train Acc : 1.000, Loss : 0.03674386 | epoch : 34000, time : 00:14:50\n",
      "Test  Acc : 0.823, Loss : 1.39729989\n",
      "Train Acc : 1.000, Loss : 0.03596040 | epoch : 35000, time : 00:15:16\n",
      "Test  Acc : 0.824, Loss : 1.39291730\n",
      "Train Acc : 1.000, Loss : 0.03520714 | epoch : 36000, time : 00:15:42\n",
      "Test  Acc : 0.825, Loss : 1.38842780\n",
      "Train Acc : 1.000, Loss : 0.03448211 | epoch : 37000, time : 00:16:08\n",
      "Test  Acc : 0.826, Loss : 1.38384211\n",
      "Train Acc : 1.000, Loss : 0.03378345 | epoch : 38000, time : 00:16:34\n",
      "Test  Acc : 0.827, Loss : 1.37916900\n",
      "Train Acc : 1.000, Loss : 0.03310938 | epoch : 39000, time : 00:17:00\n",
      "Test  Acc : 0.827, Loss : 1.37441655\n",
      "Train Acc : 1.000, Loss : 0.03245826 | epoch : 40000, time : 00:17:26\n",
      "Test  Acc : 0.829, Loss : 1.36959264\n",
      "Train Acc : 1.000, Loss : 0.03182855 | epoch : 41000, time : 00:17:52\n",
      "Test  Acc : 0.830, Loss : 1.36470503\n",
      "Train Acc : 1.000, Loss : 0.03121883 | epoch : 42000, time : 00:18:18\n",
      "Test  Acc : 0.831, Loss : 1.35976138\n",
      "Train Acc : 1.000, Loss : 0.03062782 | epoch : 43000, time : 00:18:44\n",
      "Test  Acc : 0.832, Loss : 1.35476915\n",
      "Train Acc : 1.000, Loss : 0.03005428 | epoch : 44000, time : 00:19:10\n",
      "Test  Acc : 0.833, Loss : 1.34973559\n",
      "Train Acc : 1.000, Loss : 0.02949709 | epoch : 45000, time : 00:19:36\n",
      "Test  Acc : 0.834, Loss : 1.34466764\n",
      "Train Acc : 1.000, Loss : 0.02895514 | epoch : 46000, time : 00:20:02\n",
      "Test  Acc : 0.835, Loss : 1.33957153\n",
      "Train Acc : 1.000, Loss : 0.02842737 | epoch : 47000, time : 00:20:28\n",
      "Test  Acc : 0.835, Loss : 1.33445201\n",
      "Train Acc : 1.000, Loss : 0.02791279 | epoch : 48000, time : 00:20:53\n",
      "Test  Acc : 0.836, Loss : 1.32931047\n",
      "Train Acc : 1.000, Loss : 0.02741057 | epoch : 49000, time : 00:21:19\n",
      "Test  Acc : 0.836, Loss : 1.32414243\n",
      "Train Acc : 1.000, Loss : 0.02692032 | epoch : 50000, time : 00:21:45\n",
      "Test  Acc : 0.837, Loss : 1.31893641\n",
      "Train Acc : 1.000, Loss : 0.02644218 | epoch : 51000, time : 00:22:10\n",
      "Test  Acc : 0.838, Loss : 1.31367964\n",
      "Train Acc : 1.000, Loss : 0.02597662 | epoch : 52000, time : 00:22:36\n",
      "Test  Acc : 0.839, Loss : 1.30837014\n",
      "Train Acc : 1.000, Loss : 0.02552387 | epoch : 53000, time : 00:23:02\n",
      "Test  Acc : 0.839, Loss : 1.30302111\n",
      "Train Acc : 1.000, Loss : 0.02508373 | epoch : 54000, time : 00:23:28\n",
      "Test  Acc : 0.840, Loss : 1.29765161\n",
      "Train Acc : 1.000, Loss : 0.02465566 | epoch : 55000, time : 00:23:54\n",
      "Test  Acc : 0.840, Loss : 1.29227692\n",
      "Train Acc : 1.000, Loss : 0.02423906 | epoch : 56000, time : 00:24:20\n",
      "Test  Acc : 0.841, Loss : 1.28690670\n",
      "Train Acc : 1.000, Loss : 0.02383333 | epoch : 57000, time : 00:24:46\n",
      "Test  Acc : 0.843, Loss : 1.28154701\n",
      "Train Acc : 1.000, Loss : 0.02343794 | epoch : 58000, time : 00:25:12\n",
      "Test  Acc : 0.844, Loss : 1.27620219\n",
      "Train Acc : 1.000, Loss : 0.02305242 | epoch : 59000, time : 00:25:38\n",
      "Test  Acc : 0.845, Loss : 1.27087572\n",
      "Train Acc : 1.000, Loss : 0.02267633 | epoch : 60000, time : 00:26:04\n",
      "Test  Acc : 0.845, Loss : 1.26557055\n",
      "Train Acc : 1.000, Loss : 0.02230927 | epoch : 61000, time : 00:26:30\n",
      "Test  Acc : 0.845, Loss : 1.26028918\n",
      "Train Acc : 1.000, Loss : 0.02195085 | epoch : 62000, time : 00:26:56\n",
      "Test  Acc : 0.846, Loss : 1.25503373\n",
      "Train Acc : 1.000, Loss : 0.02160076 | epoch : 63000, time : 00:27:22\n",
      "Test  Acc : 0.847, Loss : 1.24980604\n",
      "Train Acc : 1.000, Loss : 0.02125865 | epoch : 64000, time : 00:27:48\n",
      "Test  Acc : 0.847, Loss : 1.24460775\n",
      "Train Acc : 1.000, Loss : 0.02092424 | epoch : 65000, time : 00:28:14\n",
      "Test  Acc : 0.848, Loss : 1.23944045\n",
      "Train Acc : 1.000, Loss : 0.02059725 | epoch : 66000, time : 00:28:40\n",
      "Test  Acc : 0.849, Loss : 1.23430569\n",
      "Train Acc : 1.000, Loss : 0.02027740 | epoch : 67000, time : 00:29:06\n",
      "Test  Acc : 0.850, Loss : 1.22920510\n",
      "Train Acc : 1.000, Loss : 0.01996447 | epoch : 68000, time : 00:29:32\n",
      "Test  Acc : 0.850, Loss : 1.22414037\n",
      "Train Acc : 1.000, Loss : 0.01965819 | epoch : 69000, time : 00:29:58\n",
      "Test  Acc : 0.850, Loss : 1.21911332\n",
      "Train Acc : 1.000, Loss : 0.01935836 | epoch : 70000, time : 00:30:24\n",
      "Test  Acc : 0.850, Loss : 1.21412586\n",
      "Train Acc : 1.000, Loss : 0.01906476 | epoch : 71000, time : 00:30:50\n",
      "Test  Acc : 0.851, Loss : 1.20917995\n",
      "Train Acc : 1.000, Loss : 0.01877718 | epoch : 72000, time : 00:31:16\n",
      "Test  Acc : 0.851, Loss : 1.20427761\n",
      "Train Acc : 1.000, Loss : 0.01849545 | epoch : 73000, time : 00:31:42\n",
      "Test  Acc : 0.852, Loss : 1.19942086\n",
      "Train Acc : 1.000, Loss : 0.01821938 | epoch : 74000, time : 00:32:08\n",
      "Test  Acc : 0.853, Loss : 1.19461166\n",
      "Train Acc : 1.000, Loss : 0.01794881 | epoch : 75000, time : 00:32:34\n",
      "Test  Acc : 0.853, Loss : 1.18985193\n",
      "Train Acc : 1.000, Loss : 0.01768359 | epoch : 76000, time : 00:33:00\n",
      "Test  Acc : 0.854, Loss : 1.18514344\n",
      "Train Acc : 1.000, Loss : 0.01742357 | epoch : 77000, time : 00:33:26\n",
      "Test  Acc : 0.855, Loss : 1.18048780\n",
      "Train Acc : 1.000, Loss : 0.01716864 | epoch : 78000, time : 00:33:52\n",
      "Test  Acc : 0.856, Loss : 1.17588645\n",
      "Train Acc : 1.000, Loss : 0.01691867 | epoch : 79000, time : 00:34:17\n",
      "Test  Acc : 0.857, Loss : 1.17134060\n",
      "Train Acc : 1.000, Loss : 0.01667358 | epoch : 80000, time : 00:34:43\n",
      "Test  Acc : 0.857, Loss : 1.16685118\n",
      "Train Acc : 1.000, Loss : 0.01643328 | epoch : 81000, time : 00:35:09\n",
      "Test  Acc : 0.859, Loss : 1.16241888\n",
      "Train Acc : 1.000, Loss : 0.01619771 | epoch : 82000, time : 00:35:37\n",
      "Test  Acc : 0.859, Loss : 1.15804411\n",
      "Train Acc : 1.000, Loss : 0.01596681 | epoch : 83000, time : 00:36:04\n",
      "Test  Acc : 0.859, Loss : 1.15372704\n",
      "Train Acc : 1.000, Loss : 0.01574055 | epoch : 84000, time : 00:36:30\n",
      "Test  Acc : 0.860, Loss : 1.14946770\n",
      "Train Acc : 1.000, Loss : 0.01551891 | epoch : 85000, time : 00:36:56\n",
      "Test  Acc : 0.860, Loss : 1.14526602\n",
      "Train Acc : 1.000, Loss : 0.01530184 | epoch : 86000, time : 00:37:23\n",
      "Test  Acc : 0.861, Loss : 1.14112195\n",
      "Train Acc : 1.000, Loss : 0.01508933 | epoch : 87000, time : 00:37:49\n",
      "Test  Acc : 0.861, Loss : 1.13703551\n",
      "Train Acc : 1.000, Loss : 0.01488133 | epoch : 88000, time : 00:38:15\n",
      "Test  Acc : 0.862, Loss : 1.13300685\n",
      "Train Acc : 1.000, Loss : 0.01467781 | epoch : 89000, time : 00:38:42\n",
      "Test  Acc : 0.862, Loss : 1.12903620\n",
      "Train Acc : 1.000, Loss : 0.01447870 | epoch : 90000, time : 00:39:08\n",
      "Test  Acc : 0.862, Loss : 1.12512389\n",
      "Train Acc : 1.000, Loss : 0.01428396 | epoch : 91000, time : 00:39:34\n",
      "Test  Acc : 0.863, Loss : 1.12127025\n",
      "Train Acc : 1.000, Loss : 0.01409351 | epoch : 92000, time : 00:40:01\n",
      "Test  Acc : 0.864, Loss : 1.11747561\n",
      "Train Acc : 1.000, Loss : 0.01390728 | epoch : 93000, time : 00:40:27\n",
      "Test  Acc : 0.865, Loss : 1.11374020\n",
      "Train Acc : 1.000, Loss : 0.01372520 | epoch : 94000, time : 00:40:56\n",
      "Test  Acc : 0.865, Loss : 1.11006421\n",
      "Train Acc : 1.000, Loss : 0.01354717 | epoch : 95000, time : 00:41:23\n",
      "Test  Acc : 0.866, Loss : 1.10644770\n",
      "Train Acc : 1.000, Loss : 0.01337314 | epoch : 96000, time : 00:41:49\n",
      "Test  Acc : 0.866, Loss : 1.10289066\n",
      "Train Acc : 1.000, Loss : 0.01320300 | epoch : 97000, time : 00:42:15\n",
      "Test  Acc : 0.867, Loss : 1.09939298\n",
      "Train Acc : 1.000, Loss : 0.01303667 | epoch : 98000, time : 00:42:42\n",
      "Test  Acc : 0.868, Loss : 1.09595449\n",
      "Train Acc : 1.000, Loss : 0.01287409 | epoch : 99000, time : 00:43:08\n",
      "Test  Acc : 0.868, Loss : 1.09257495\n",
      "Train Acc : 1.000, Loss : 0.01271515 | epoch : 100000, time : 00:43:35\n",
      "Test  Acc : 0.868, Loss : 1.08925406\n",
      "Train Acc : 1.000, Loss : 0.01255979 | epoch : 101000, time : 00:44:04\n",
      "Test  Acc : 0.868, Loss : 1.08599153\n",
      "Train Acc : 1.000, Loss : 0.01240791 | epoch : 102000, time : 00:44:31\n",
      "Test  Acc : 0.868, Loss : 1.08278698\n",
      "Train Acc : 1.000, Loss : 0.01225945 | epoch : 103000, time : 00:44:58\n",
      "Test  Acc : 0.868, Loss : 1.07964006\n",
      "Train Acc : 1.000, Loss : 0.01211433 | epoch : 104000, time : 00:45:25\n",
      "Test  Acc : 0.869, Loss : 1.07655037\n",
      "Train Acc : 1.000, Loss : 0.01197247 | epoch : 105000, time : 00:45:53\n",
      "Test  Acc : 0.869, Loss : 1.07351751\n",
      "Train Acc : 1.000, Loss : 0.01183379 | epoch : 106000, time : 00:46:20\n",
      "Test  Acc : 0.870, Loss : 1.07054106\n",
      "Train Acc : 1.000, Loss : 0.01169823 | epoch : 107000, time : 00:46:48\n",
      "Test  Acc : 0.870, Loss : 1.06762060\n",
      "Train Acc : 1.000, Loss : 0.01156571 | epoch : 108000, time : 00:47:15\n",
      "Test  Acc : 0.871, Loss : 1.06475566\n",
      "Train Acc : 1.000, Loss : 0.01143615 | epoch : 109000, time : 00:47:43\n",
      "Test  Acc : 0.871, Loss : 1.06194582\n",
      "Train Acc : 1.000, Loss : 0.01130949 | epoch : 110000, time : 00:48:10\n",
      "Test  Acc : 0.871, Loss : 1.05919062\n",
      "Train Acc : 1.000, Loss : 0.01118566 | epoch : 111000, time : 00:48:37\n",
      "Test  Acc : 0.872, Loss : 1.05648961\n",
      "Train Acc : 1.000, Loss : 0.01106458 | epoch : 112000, time : 00:49:05\n",
      "Test  Acc : 0.873, Loss : 1.05384234\n",
      "Train Acc : 1.000, Loss : 0.01094619 | epoch : 113000, time : 00:49:32\n",
      "Test  Acc : 0.873, Loss : 1.05124841\n",
      "Train Acc : 1.000, Loss : 0.01083042 | epoch : 114000, time : 00:49:59\n",
      "Test  Acc : 0.873, Loss : 1.04870740\n",
      "Train Acc : 1.000, Loss : 0.01071720 | epoch : 115000, time : 00:50:26\n",
      "Test  Acc : 0.873, Loss : 1.04621895\n"
     ]
    }
   ],
   "source": [
    "ml2 = ML([196,49,10],lr= 1e-4,loss_conv = 1e-9,weight_decay=1e-1,monitoring_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml3 = ML([196,49,10],lr= 1e-5,loss_conv = 1e-9,weight_decay=4e-1,monitoring_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml3.show_loss_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml3.show_acc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml3.show_incorrect_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml4 = ML([1000,500,196,49,10],lr= 1e-3,loss_conv = 1e-9,weight_decay=1e-1,monitoring_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_correct_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_incorrect_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_final_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_loss_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_acc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml3 = ML([196,49,10],lr= 1e-3,loss_conv = 1e-7,weight_decay=1e-2,monitoring_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml4 = ML([1400,700,400,250,130,60,30,10],lr= 1e-3,loss_conv = 1e-7,weight_decay=1e-4,monitoring_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml2.show_final_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_correct_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_incorrect_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_loss_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_acc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_final_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for show examples\n",
    "list_correct_image = np.array(result_test[\"correct_image\"]).T\n",
    "list_correct_label = result_test[\"correct_label\"]\n",
    "list_incorrect_image = np.array(result_test[\"incorrect_image\"]).T\n",
    "list_incorrect_label = result_test[\"incorrect_label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Loss curve\")\n",
    "plot_1, = plt.plot(result_train[\"epoch\"],result_train[\"loss\"], color='b',linewidth=2,alpha=0.8)\n",
    "plot_2, = plt.plot(result_test[\"epoch\"],result_test[\"loss\"], color='r',linewidth=2,alpha=0.8)\n",
    "plt.legend([plot_1,plot_2],[\"Training\",\"Testing\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the accuracy curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Accuracy curve\")\n",
    "plot_1, = plt.plot(result_train[\"epoch\"],result_train[\"acc\"], color='b',linewidth=2,alpha=0.8)\n",
    "plot_2, = plt.plot(result_test[\"epoch\"],result_test[\"acc\"], color='r',linewidth=2,alpha=0.8)\n",
    "plt.legend([plot_1,plot_2],[\"Training\",\"Testing\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the accuracy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Training Acc : {:.3f}%\\nFinal Testing Acc : {:.3f}%\".format(result_train[\"acc\"][-1]*100,result_test[\"acc\"][-1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the classification example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctly classified testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(list_correct_image,list_correct_label)\n",
    "print(list_correct_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misclassified testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(list_incorrect_image,list_incorrect_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
