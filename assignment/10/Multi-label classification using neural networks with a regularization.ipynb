{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multi-label classification using neural networks with a regularization\n",
    "* Writer : Jesoon Kang, Chung-Ang University\n",
    "* last-modified date : June 4, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import math\n",
    "from IPython.display import display, Math, Latex\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Opening data file\n",
    "\n",
    "file_data   = \"mnist.csv\"\n",
    "handle_file = open(file_data, \"r\")\n",
    "data        = handle_file.readlines()\n",
    "handle_file.close()\n",
    "\n",
    "size_row    = 28    # height of the image\n",
    "size_col    = 28    # width of the image\n",
    "\n",
    "num_image   = len(data)\n",
    "count       = 0     # count for the number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2060 SUPER\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "### Setting up Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Below codes activates when want to use cpu\n",
    "#device = torch.device('cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# normalize the values of the input data to be [0, 1]\n",
    "#\n",
    "def normalize(data):\n",
    "\n",
    "    data_normalized = (data - min(data)) / (max(data) - min(data))\n",
    "\n",
    "    return(data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# example of distance function between two vectors x and y\n",
    "#\n",
    "def distance(x, y):\n",
    "\n",
    "    d = (x - y) ** 2\n",
    "    s = np.sum(d)\n",
    "    # r = np.sqrt(s)\n",
    "\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# make a matrix each column of which represents an images in a vector form\n",
    "#\n",
    "list_image  = np.empty((size_row * size_col, num_image), dtype=float)\n",
    "list_label  = np.empty(num_image, dtype=int)\n",
    "\n",
    "for line in data:\n",
    "\n",
    "    line_data   = line.split(',')\n",
    "    label       = line_data[0]\n",
    "    im_vector   = np.asfarray(line_data[1:])\n",
    "    im_vector   = normalize(im_vector)\n",
    "\n",
    "    list_label[count]       = label\n",
    "    list_image[:, count]    = im_vector\n",
    "\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(z):\n",
    "    sig_value =  1.0 / (1.0 + np.exp(-z))\n",
    "    return sig_value * (1 - sig_value)\n",
    "\n",
    "# Return derivative of in\n",
    "def sig_grad(z) :\n",
    "    return z * (1-z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to getting running time\n",
    "def get_running_time(start_time) :\n",
    "    running_time = datetime.datetime.now() - start_time\n",
    "    running_time = running_time.seconds\n",
    "    hours, remainder = divmod(running_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return hours, minutes, seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Make image, label data to tensor type\n",
    "train_image = list_image[:, :1000]\n",
    "train_label = list_label[:1000]\n",
    "test_image = list_image[:,1000:]\n",
    "test_label = list_label[1000:]\n",
    "\n",
    "train_label_vec = np.zeros((10, train_label.shape[0]))\n",
    "test_label_vec = np.zeros((10, test_label.shape[0]))\n",
    "for i, val in enumerate(train_label):\n",
    "    train_label_vec[val, i] = 1.0\n",
    "for i, val in enumerate(test_label):\n",
    "    test_label_vec[val, i] = 1.0\n",
    "\n",
    "    \n",
    "train_input_with_bias = np.ones((train_image.shape[0]+1, train_image.shape[1])) # add bia\n",
    "train_input_with_bias[1:, :] = train_image\n",
    "test_input_with_bias = np.ones((test_image.shape[0]+1, test_image.shape[1])) # add bia\n",
    "test_input_with_bias[1:, :] = test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data to tensor\n",
    "train_input_with_bias = torch.DoubleTensor(train_input_with_bias).to(device)\n",
    "test_input_with_bias = torch.DoubleTensor(test_input_with_bias).to(device)\n",
    "train_label_vec = torch.DoubleTensor(train_label_vec).to(device)\n",
    "test_label_vec = torch.DoubleTensor(test_label_vec).to(device)\n",
    "train_label = torch.DoubleTensor(train_label).to(device)\n",
    "test_label = torch.DoubleTensor(test_label).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML :\n",
    "    def __init__(self,layer_info = [196,49,10],lr = 1e-3,weight_decay= 1e-4,loss_conv = 1e-6,monitoring_epoch = 0) :\n",
    "        print('-'*20,\"ML START\", '-'*20)\n",
    "        \n",
    "        \n",
    "        print(\"lr : {}, weight_decay : {}, loss_conv : {}, thetas : {}\".format(lr, weight_decay, loss_conv, layer_info))\n",
    "        self.list_layer_info = layer_info\n",
    "        self.init_thetas()\n",
    "        \n",
    "        # Get number of thetas(total)\n",
    "        self.th_num = 0\n",
    "        for th in self.list_theta :\n",
    "            self.th_num += th.view(-1).shape[0]\n",
    "        \n",
    "        # Initial variable setting\n",
    "        self.monitoring_epoch = monitoring_epoch\n",
    "        self.num_hidden_layer = len(self.list_theta)-1\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.loss_conv = loss_conv\n",
    "        self.epoch = 0\n",
    "        self.list_epoch = []\n",
    "        self.list_loss_train = []\n",
    "        self.list_loss_test = []\n",
    "        self.list_acc_train = []\n",
    "        self.list_acc_test = []\n",
    "        self.list_y = []\n",
    "        self.list_a = []\n",
    "        self.result_train = {}\n",
    "        self.result_test = {}\n",
    "        self.start_time = datetime.datetime.now()\n",
    "        self.exit_count = 0\n",
    "        self.list_dL = []\n",
    "        self.list_grad = []\n",
    "        self.exit_count = 0\n",
    "        self.train()\n",
    "\n",
    "    # Get mean value of theta square\n",
    "    def get_mean_theta_square(self,list_theta) :\n",
    "        sum_th = 0\n",
    "        th_num = 0\n",
    "        for th in list_theta :\n",
    "            sum_th += torch.sum(th**2)\n",
    "            th_num += th.view(-1).shape[0]\n",
    "        return sum_th/self.th_num\n",
    "    \n",
    "    # Initialize theta\n",
    "    def init_thetas(self) :\n",
    "        self.list_theta = []\n",
    "        list_d = [784]\n",
    "        for d in self.list_layer_info :\n",
    "            th = torch.randn((d,list_d[-1]+1),dtype=torch.double).to(device)\n",
    "            self.list_theta.append(th)\n",
    "            list_d.append(d)\n",
    "        \n",
    "    # monitoring \n",
    "    def monitoring(self) :\n",
    "        if self.monitoring_epoch != 0 :\n",
    "            if self.epoch % self.monitoring_epoch == 0 :\n",
    "                running_time = get_running_time(self.start_time)\n",
    "                print(\"Train Acc : {:.3f}, Loss : {:.8f} | epoch : {}, time : {:02d}:{:02d}:{:02d}\\nTest  Acc : {:.3f}, Loss : {:.8f}\".\\\n",
    "                      format(self.list_acc_train[-1],self.list_loss_train[-1],self.epoch,running_time[0],running_time[1],running_time[2],self.list_acc_test[-1],self.list_loss_test[-1]))\n",
    "        \n",
    "    # Train.\n",
    "    def train(self) :\n",
    "        while (True) :\n",
    "            self.forward_propagation_train()\n",
    "            self.set_gradient_decent()\n",
    "            self.forward_propagation_test()\n",
    "            self.update_weights()\n",
    "            self.monitoring()\n",
    "            \n",
    "            if self.check_terminate() :\n",
    "                self.terminate()\n",
    "                break\n",
    "        \n",
    "\n",
    "    # Check the loss gap\n",
    "    def check_terminate(self) :\n",
    "        if self.epoch > 5 :\n",
    "            loss_gap = abs(self.list_loss_train[-1] - self.list_loss_train[-2])\n",
    "            if loss_gap < self.loss_conv :\n",
    "                self.exit_count += 1\n",
    "            else :\n",
    "                self.exit_count = 0\n",
    "            if self.exit_count > 4 :\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    # Terminate Train. Save example data\n",
    "    def terminate(self) :\n",
    "        # Save result.\n",
    "        self.result_train[\"epoch\"] = self.list_epoch\n",
    "        self.result_train[\"loss\"] = self.list_loss_train\n",
    "        self.result_train[\"acc\"] = self.list_acc_train\n",
    "        self.result_train[\"theta\"] = self.list_theta\n",
    "\n",
    "        self.result_test[\"epoch\"] = self.list_epoch\n",
    "        self.result_test[\"loss\"] = self.list_loss_test\n",
    "        self.result_test[\"acc\"] = self.list_acc_test\n",
    "\n",
    "        # Save Sample images\n",
    "        list_correct_image = []\n",
    "        list_correct_label = []\n",
    "        list_incorrect_image = []\n",
    "        list_incorrect_label = []\n",
    "        num_correct=0\n",
    "        num_incorrect=0\n",
    "\n",
    "        # Save correct images\n",
    "        for i, correct in enumerate(test_label == self.predict_test) :\n",
    "            if (correct) :\n",
    "                if num_correct < 10 :\n",
    "                    list_correct_image.append(test_image[:,i])\n",
    "                    list_correct_label.append(int(test_label[i].item()))\n",
    "                    num_correct += 1\n",
    "            else :\n",
    "                # Save incorrect images\n",
    "                if num_incorrect < 10 :\n",
    "                    list_incorrect_image.append(test_image[:,i])\n",
    "                    list_incorrect_label.append(int(self.predict_test[i].item()))\n",
    "                    num_incorrect += 1\n",
    "            if num_correct >= 10 and num_incorrect >= 10 :\n",
    "                break\n",
    "        self.result_test[\"correct_image\"] = list_correct_image\n",
    "        self.result_test[\"correct_label\"] = list_correct_label\n",
    "        self.result_test[\"incorrect_image\"] = list_incorrect_image\n",
    "        self.result_test[\"incorrect_label\"] = list_incorrect_label\n",
    "\n",
    "        print(\"Loss is converged. epoch {}\".format(self.epoch))\n",
    "        print(\"Training Process Ended\")\n",
    "        return True\n",
    "        \n",
    "    # Forward propagation on train data\n",
    "    def forward_propagation_train(self) :\n",
    "        self.epoch += 1\n",
    "        self.list_epoch.append(self.epoch)\n",
    "        self.list_y = []\n",
    "        self.list_a = []\n",
    "        self.list_a_bias = [train_input_with_bias]\n",
    "        for idx, th in enumerate(self.list_theta) :    \n",
    "            y_tmp = torch.mm(th,self.list_a_bias[-1])\n",
    "            self.list_y.append(y_tmp)\n",
    "            a_tmp = 1 / (1 + torch.exp(-y_tmp))\n",
    "            self.list_a.append(a_tmp)\n",
    "            a_bias_tmp = torch.ones((a_tmp.shape[0] + 1, a_tmp.shape[1]), dtype=torch.double).to(device)\n",
    "            a_bias_tmp[1:, :] = a_tmp\n",
    "            self.list_a_bias.append(a_bias_tmp)\n",
    "        self.list_a_bias.pop()\n",
    "        \n",
    "        h = self.list_a[-1]\n",
    "        \n",
    "        # Get Loss value with L2 regulazation\n",
    "        loss_train = torch.sum(-train_label_vec * (torch.log(h)) - (1 - train_label_vec)* torch.log(1 - h)) / len(h.T) + self.weight_decay*0.5*self.get_mean_theta_square(self.list_theta)\n",
    "        self.list_loss_train.append(loss_train)\n",
    "        \n",
    "        # Calculate Acc\n",
    "        self.predict_train = torch.argmax(h, axis = 0)\n",
    "        self.correct_train = torch.sum(train_label == self.predict_train, axis = 0)\n",
    "        acc_train = self.correct_train.item()/train_label.shape[0]\n",
    "        self.list_acc_train.append(acc_train)\n",
    "        \n",
    "    # Forward propagation in test data\n",
    "    def forward_propagation_test(self) :\n",
    "        \n",
    "        self.list_y = []\n",
    "        self.list_a = []\n",
    "        self.list_a_bias = [test_input_with_bias]\n",
    "        for idx, th in enumerate(self.list_theta) :\n",
    "           \n",
    "            y_tmp = torch.mm(th,self.list_a_bias[-1])\n",
    "            self.list_y.append(y_tmp)\n",
    "            a_tmp = 1 / (1 + torch.exp(-y_tmp))\n",
    "            self.list_a.append(a_tmp)\n",
    "            a_bias_tmp = torch.ones((a_tmp.shape[0] + 1, a_tmp.shape[1]), dtype=torch.double).to(device)\n",
    "            a_bias_tmp[1:, :] = a_tmp\n",
    "            self.list_a_bias.append(a_bias_tmp)\n",
    "        self.list_a_bias.pop()\n",
    "        \n",
    "        h = self.list_a[-1]\n",
    "        \n",
    "        # Get Loss value with L2 regulazation\n",
    "        loss_test = torch.sum(-test_label_vec * (torch.log(h)) - (1 - test_label_vec)* torch.log(1 - h)) / len(h.T) + self.weight_decay*0.5*self.get_mean_theta_square(self.list_theta)\n",
    "        self.list_loss_test.append(loss_test)\n",
    "\n",
    "\n",
    "        # Calculate Acc\n",
    "        self.predict_test = torch.argmax(h, axis = 0)\n",
    "        self.correct_test = torch.sum(test_label == self.predict_test, axis = 0)\n",
    "        acc_test = self.correct_test.item()/test_label.shape[0]\n",
    "        self.list_acc_test.append(acc_test)\n",
    "        \n",
    "    def set_gradient_decent (self) :\n",
    "         # Back propagation\n",
    "        self.list_dL = []\n",
    "        self.list_grad = []\n",
    "        \n",
    "        self.list_dL.append(self.list_a[-1]-train_label_vec)\n",
    "        grad = torch.mm(self.list_dL[-1],self.list_a_bias[-1].T) + self.weight_decay*0.5*self.list_theta[-1]#/self.th_num\n",
    "        \n",
    "        self.list_grad.append(torch.mm(self.list_dL[-1],self.list_a_bias[-1].T))\n",
    "        idx = 0\n",
    "        # Calculate gradient decent in order from back-end\n",
    "        for i in range(0,self.num_hidden_layer) :\n",
    "            idx += 1\n",
    "            dL_dy = torch.mm(self.list_theta[-idx].T,self.list_dL[-1]) * sig_grad(self.list_a_bias[-idx])\n",
    "            dL_dy = dL_dy[1:, :]\n",
    "            self.list_dL.append(dL_dy)\n",
    "           \n",
    "            # Get gradient decent value \n",
    "            grad = torch.mm(dL_dy, self.list_a_bias[-(idx+1)].T)\n",
    "            # Applying L2 Regulazation \n",
    "            grad_2 = self.weight_decay*self.list_theta[-(idx+1)]#/self.th_num\n",
    "            grad = grad + grad_2\n",
    "            self.list_grad.append(grad)\n",
    "        self.list_grad.reverse()\n",
    "        \n",
    "        # Update weights \n",
    "    def update_weights(self) :\n",
    "        for th, grad in zip(self.list_theta,self.list_grad) :\n",
    "            th -= self.lr * (grad)\n",
    "            \n",
    "    def show_correct_example(self) :\n",
    "\n",
    "        list_label = self.result_test[\"correct_label\"]\n",
    "        list_image = np.array(self.result_test[\"correct_image\"]).T\n",
    "        f1 = plt.figure(1)\n",
    "\n",
    "        for i in range(10):\n",
    "            label       = list_label[i]\n",
    "            im_vector   = list_image[:, i]\n",
    "            im_matrix   = im_vector.reshape((size_row, size_col))\n",
    "\n",
    "            plt.subplot(2, 5, i+1)\n",
    "            plt.title(label)\n",
    "            plt.imshow(im_matrix, cmap='Greys', interpolation='None')\n",
    "\n",
    "            frame   = plt.gca()\n",
    "            frame.axes.get_xaxis().set_visible(False)\n",
    "            frame.axes.get_yaxis().set_visible(False)\n",
    "        plt.show()    \n",
    "\n",
    "    def show_incorrect_example(self) :\n",
    "\n",
    "        list_label = self.result_test[\"incorrect_label\"]\n",
    "        list_image = np.array(self.result_test[\"incorrect_image\"]).T\n",
    "        f1 = plt.figure(1)\n",
    "\n",
    "        for i in range(10):\n",
    "            label       = list_label[i]\n",
    "            im_vector   = list_image[:, i]\n",
    "            im_matrix   = im_vector.reshape((size_row, size_col))\n",
    "\n",
    "            plt.subplot(2, 5, i+1)\n",
    "            plt.title(label)\n",
    "            plt.imshow(im_matrix, cmap='Greys', interpolation='None')\n",
    "\n",
    "            frame   = plt.gca()\n",
    "            frame.axes.get_xaxis().set_visible(False)\n",
    "            frame.axes.get_yaxis().set_visible(False)\n",
    "        plt.show()    \n",
    "    def show_loss_curve(self) :\n",
    "        plt.title(\"Loss curve\")\n",
    "        plot_1, = plt.plot(self.result_train[\"epoch\"],self.result_train[\"loss\"], color='b',linewidth=2,alpha=0.8)\n",
    "        plot_2, = plt.plot(self.result_test[\"epoch\"],self.result_test[\"loss\"], color='r',linewidth=2,alpha=0.8)\n",
    "        plt.legend([plot_1,plot_2],[\"Training\",\"Testing\"])\n",
    "\n",
    "    def show_acc_curve(self) :\n",
    "        plt.title(\"Accuracy curve\")\n",
    "        plot_1, = plt.plot(self.result_train[\"epoch\"],self.result_train[\"acc\"], color='b',linewidth=2,alpha=0.8)\n",
    "        plot_2, = plt.plot(self.result_test[\"epoch\"],self.result_test[\"acc\"], color='r',linewidth=2,alpha=0.8)\n",
    "        plt.legend([plot_1,plot_2],[\"Training\",\"Testing\"])\n",
    "\n",
    "    def show_final_acc(self) :\n",
    "        print(\"Final Training Acc : {:.3f}%\\nFinal Testing Acc : {:.3f}%\".format(self.result_train[\"acc\"][-1]*100,self.result_test[\"acc\"][-1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [196, 49, 10]\n",
      "Train Acc : 1.000, Loss : 0.13906103 | epoch : 1000, time : 00:00:27\n",
      "Test  Acc : 0.819, Loss : 1.32895788\n",
      "Train Acc : 1.000, Loss : 0.06640770 | epoch : 2000, time : 00:00:53\n",
      "Test  Acc : 0.857, Loss : 1.07051099\n",
      "Train Acc : 1.000, Loss : 0.04054487 | epoch : 3000, time : 00:01:20\n",
      "Test  Acc : 0.879, Loss : 0.91106357\n",
      "Train Acc : 1.000, Loss : 0.02964401 | epoch : 4000, time : 00:01:47\n",
      "Test  Acc : 0.887, Loss : 0.84882608\n",
      "Train Acc : 1.000, Loss : 0.02452521 | epoch : 5000, time : 00:02:15\n",
      "Test  Acc : 0.889, Loss : 0.84548215\n",
      "Train Acc : 1.000, Loss : 0.07287512 | epoch : 6000, time : 00:02:42\n",
      "Test  Acc : 0.891, Loss : 0.70540719\n",
      "Train Acc : 1.000, Loss : 0.03061793 | epoch : 7000, time : 00:03:09\n",
      "Test  Acc : 0.892, Loss : 0.75517663\n",
      "Train Acc : 1.000, Loss : 0.02335604 | epoch : 8000, time : 00:03:36\n",
      "Test  Acc : 0.891, Loss : 0.80060296\n",
      "Train Acc : 1.000, Loss : 0.01976579 | epoch : 9000, time : 00:04:03\n",
      "Test  Acc : 0.889, Loss : 0.84880561\n",
      "Train Acc : 1.000, Loss : 0.01807820 | epoch : 10000, time : 00:04:30\n",
      "Test  Acc : 0.888, Loss : 0.88519242\n",
      "Train Acc : 1.000, Loss : 0.01691306 | epoch : 11000, time : 00:04:57\n",
      "Test  Acc : 0.887, Loss : 0.91354101\n",
      "Train Acc : 0.944, Loss : 0.41143493 | epoch : 12000, time : 00:05:23\n",
      "Test  Acc : 0.823, Loss : 1.17439330\n",
      "Train Acc : 1.000, Loss : 0.01934655 | epoch : 13000, time : 00:05:50\n",
      "Test  Acc : 0.890, Loss : 0.84016105\n",
      "Train Acc : 1.000, Loss : 0.01844660 | epoch : 14000, time : 00:06:17\n",
      "Test  Acc : 0.889, Loss : 0.85866092\n",
      "Train Acc : 1.000, Loss : 0.01750659 | epoch : 15000, time : 00:06:45\n",
      "Test  Acc : 0.888, Loss : 0.88013379\n"
     ]
    }
   ],
   "source": [
    "ml = ML([196,49,10],lr= 1e-3,loss_conv = 1e-7,weight_decay=4e-1,monitoring_epoch=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_loss_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the accuracy curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_acc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the accuracy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_final_acc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the classification example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctly classified testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_correct_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misclassified testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_incorrect_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
