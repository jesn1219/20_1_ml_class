{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multi-label classification using neural networks with a regularization\n",
    "* Writer : Jesoon Kang, Chung-Ang University\n",
    "* last-modified date : June 4, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import math\n",
    "from IPython.display import display, Math, Latex\n",
    "import os\n",
    "import time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = load_files(r\"movie_review\")\n",
    "X, y = review_data.data, review_data.target\n",
    "\n",
    "documents = []\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10000, min_df=5, max_df=0.5, stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()\n",
    "\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1401, 10000) (601, 10000) (1401,) (601,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce RTX 2060 SUPER\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "### Setting up Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Below codes activates when want to use cpu\n",
    "#device = torch.device('cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(z):\n",
    "    sig_value =  1.0 / (1.0 + np.exp(-z))\n",
    "    return sig_value * (1 - sig_value)\n",
    "\n",
    "# Return derivative of in\n",
    "def sig_grad(z) :\n",
    "    return z * (1-z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to getting running time\n",
    "def get_running_time(start_time) :\n",
    "    running_time = datetime.datetime.now() - start_time\n",
    "    running_time = running_time.seconds\n",
    "    hours, remainder = divmod(running_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return hours, minutes, seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {}\n",
    "\n",
    "def preprocess_data(max_features, min_df, max_df) :\n",
    "\n",
    "    review_data = load_files(r\"movie_review\")\n",
    "    X, y = review_data.data, review_data.target\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    stemmer = WordNetLemmatizer()\n",
    "\n",
    "    for sen in range(0, len(X)):\n",
    "        # Remove all the special characters\n",
    "        document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "\n",
    "        # remove all single characters\n",
    "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "        # Remove single characters from the start\n",
    "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "        # Removing prefixed 'b'\n",
    "        document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "        # Converting to Lowercase\n",
    "        document = document.lower()\n",
    "\n",
    "        # Lemmatization\n",
    "        document = document.split()\n",
    "        document = [stemmer.lemmatize(word) for word in document]\n",
    "        document = ' '.join(document)\n",
    "\n",
    "        documents.append(document)\n",
    "\n",
    "    vectorizer = CountVectorizer(max_features=max_features, min_df=min_df, max_df=max_df, stop_words=stopwords.words('english'))\n",
    "    X = vectorizer.fit_transform(documents).toarray()\n",
    "\n",
    "    tfidfconverter = TfidfTransformer()\n",
    "    X = tfidfconverter.fit_transform(X).toarray()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "    # Make image, label data to tensor type\n",
    "    train_input = X_train.T\n",
    "    train_label = y_train\n",
    "    test_input = X_test.T\n",
    "    test_label = y_test\n",
    "    train_label_vec = train_label\n",
    "    test_label_vec = test_label\n",
    "    train_input_with_bias = np.ones((train_input.shape[0]+1, train_input.shape[1])) # add bia\n",
    "    train_input_with_bias[1:, :] = train_input\n",
    "    test_input_with_bias = np.ones((test_input.shape[0]+1, test_input.shape[1])) # add bia\n",
    "    test_input_with_bias[1:, :] = test_input\n",
    "\n",
    "    # Make data to tensor\n",
    "    data[\"train_input_with_bias\"] = torch.DoubleTensor(train_input_with_bias).to(device)\n",
    "    data[\"test_input_with_bias\"] = torch.DoubleTensor(test_input_with_bias).to(device)\n",
    "    data[\"train_label_vec\"] = torch.DoubleTensor(train_label_vec).to(device)\n",
    "    data[\"test_label_vec\"] = torch.DoubleTensor(test_label_vec).to(device)\n",
    "    data[\"train_input\"] = torch.DoubleTensor(train_input).to(device)\n",
    "    data[\"test_input\"] = torch.DoubleTensor(test_input).to(device)\n",
    "    data[\"train_label\"] = torch.DoubleTensor(train_label).to(device)\n",
    "    data[\"test_label\"] = torch.DoubleTensor(test_label).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make image, label data to tensor type\n",
    "train_image = X_train.T\n",
    "train_label = y_train\n",
    "test_image = X_test.T\n",
    "test_label = y_test\n",
    "train_label_vec = train_label\n",
    "test_label_vec = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_with_bias = np.ones((train_image.shape[0]+1, train_image.shape[1])) # add bia\n",
    "train_input_with_bias[1:, :] = train_image\n",
    "test_input_with_bias = np.ones((test_image.shape[0]+1, test_image.shape[1])) # add bia\n",
    "test_input_with_bias[1:, :] = test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data to tensor\n",
    "train_input_with_bias = torch.DoubleTensor(train_input_with_bias).to(device)\n",
    "test_input_with_bias = torch.DoubleTensor(test_input_with_bias).to(device)\n",
    "train_label_vec = torch.DoubleTensor(train_label_vec).to(device)\n",
    "test_label_vec = torch.DoubleTensor(test_label_vec).to(device)\n",
    "train_label = torch.DoubleTensor(train_label).to(device)\n",
    "test_label = torch.DoubleTensor(test_label).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_classifier :\n",
    "    def __init__(self,data, layer_info = [196,49,10],lr = 1e-3,weight_decay= 1e-4,loss_conv = 1e-6,monitoring_epoch = 0) :\n",
    "        print('-'*20,\"ML START\", '-'*20)\n",
    "        \n",
    "        \n",
    "        self.feature_size = data[\"train_input\"].shape[0]\n",
    "        \n",
    "        print(\"lr : {}, weight_decay : {}, loss_conv : {}, thetas : {}\".format(lr, weight_decay, loss_conv, layer_info))\n",
    "        self.list_layer_info = layer_info\n",
    "        self.init_thetas()\n",
    "        # Get number of thetas(total)\n",
    "        self.th_num = 0\n",
    "        for th in self.list_theta :\n",
    "            self.th_num += th.view(-1).shape[0]\n",
    "        \n",
    "        # Initial variable setting\n",
    "        self.monitoring_epoch = monitoring_epoch\n",
    "        self.num_hidden_layer = len(self.list_theta)-1\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.loss_conv = loss_conv\n",
    "        self.epoch = 0\n",
    "        self.list_epoch = []\n",
    "        self.list_loss_train = []\n",
    "        self.list_loss_test = []\n",
    "        self.list_pred_train = []\n",
    "        self.list_pred_test = []\n",
    "        self.list_acc_train = []\n",
    "        self.list_acc_test = []\n",
    "        self.list_y = []\n",
    "        self.list_a = []\n",
    "        self.result_train = {}\n",
    "        self.result_test = {}\n",
    "        self.start_time = datetime.datetime.now()\n",
    "        self.exit_count = 0\n",
    "        self.list_dL = []\n",
    "        self.list_grad = []\n",
    "        self.exit_count = 0\n",
    "        self.top_acc = 0\n",
    "        self.train()\n",
    "\n",
    "    # Get mean value of theta square\n",
    "    def get_mean_theta_square(self,list_theta) :\n",
    "        sum_th = 0\n",
    "        th_num = 0\n",
    "        for th in list_theta :\n",
    "            sum_th += torch.sum(th**2)\n",
    "            th_num += th.view(-1).shape[0]\n",
    "        return sum_th/self.th_num\n",
    "    \n",
    "    # Initialize theta\n",
    "    def init_thetas(self) :\n",
    "        self.list_theta = []\n",
    "        list_d = []\n",
    "        list_d.append(self.feature_size)\n",
    "        for d in self.list_layer_info :\n",
    "            th = torch.randn((d,list_d[-1]+1),dtype=torch.double).to(device)\n",
    "            self.list_theta.append(th)\n",
    "            list_d.append(d)\n",
    "    \n",
    "        \n",
    "    # monitoring \n",
    "    def monitoring(self) :\n",
    "        if self.monitoring_epoch != 0 :\n",
    "            if self.epoch % self.monitoring_epoch == 0 :\n",
    "                running_time = get_running_time(self.start_time)\n",
    "                print(\"Train Acc : {:.3f}, Loss : {:.8f} | epoch : {}, time : {:02d}:{:02d}:{:02d}\\nTest  Acc : {:.3f}, Loss : {:.8f}\".\\\n",
    "                      format(self.list_acc_train[-1],self.list_loss_train[-1],self.epoch,running_time[0],running_time[1],running_time[2],self.list_acc_test[-1],self.list_loss_test[-1]))\n",
    "        \n",
    "    # Train.\n",
    "    def train(self) :\n",
    "        while (True) :\n",
    "            self.forward_propagation_train()\n",
    "            self.set_gradient_decent()\n",
    "            self.forward_propagation_test()\n",
    "            self.update_weights()\n",
    "            self.monitoring()\n",
    "            self.check_top_acc()\n",
    "            if self.check_terminate() :\n",
    "                self.terminate()\n",
    "                break\n",
    "        \n",
    "\n",
    "    # Check the loss gap\n",
    "    def check_terminate(self) :\n",
    "        if self.epoch > 5 :\n",
    "            loss_gap = abs(self.list_loss_train[-1] - self.list_loss_train[-2])\n",
    "            if loss_gap < self.loss_conv :\n",
    "                self.exit_count += 1\n",
    "            else :\n",
    "                self.exit_count = 0\n",
    "            if self.exit_count > 4 :\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    # Terminate Train. Save example data\n",
    "    def terminate(self) :\n",
    "        # Save result.\n",
    "        self.result_train[\"epoch\"] = self.list_epoch\n",
    "        self.result_train[\"loss\"] = self.list_loss_train\n",
    "        self.result_train[\"acc\"] = self.list_acc_train\n",
    "        self.result_train[\"theta\"] = self.list_theta\n",
    "\n",
    "        self.result_test[\"epoch\"] = self.list_epoch\n",
    "        self.result_test[\"loss\"] = self.list_loss_test\n",
    "        self.result_test[\"acc\"] = self.list_acc_test\n",
    "\n",
    "        print(\"Loss is converged. epoch {}\".format(self.epoch))\n",
    "        print(\"Training Process Ended\")\n",
    "        return True\n",
    "        \n",
    "    # Forward propagation on train data\n",
    "    def forward_propagation_train(self) :\n",
    "        self.epoch += 1\n",
    "        self.list_epoch.append(self.epoch)\n",
    "        self.list_y = []\n",
    "        self.list_a = []\n",
    "        self.list_a_bias = [data[\"train_input_with_bias\"]]\n",
    "        for idx, th in enumerate(self.list_theta) :    \n",
    "            y_tmp = torch.mm(th,self.list_a_bias[-1])\n",
    "            self.list_y.append(y_tmp)\n",
    "            a_tmp = 1 / (1 + torch.exp(-y_tmp))\n",
    "            self.list_a.append(a_tmp)\n",
    "            a_bias_tmp = torch.ones((a_tmp.shape[0] + 1, a_tmp.shape[1]), dtype=torch.double).to(device)\n",
    "            a_bias_tmp[1:, :] = a_tmp\n",
    "            self.list_a_bias.append(a_bias_tmp)\n",
    "        self.list_a_bias.pop()\n",
    "        \n",
    "        h = self.list_a[-1]\n",
    "        \n",
    "        # Get Loss value with L2 regulazation\n",
    "        loss_train = torch.sum(-data[\"train_label_vec\"] * (torch.log(h)) - (1 - data[\"train_label_vec\"])* torch.log(1 - h)) / len(h.T) + self.weight_decay*0.5*self.get_mean_theta_square(self.list_theta)\n",
    "        self.list_loss_train.append(loss_train)\n",
    "        \n",
    "        self.pred_train = (h >=0.5)\n",
    "        self.list_pred_train.append(self.pred_train)\n",
    "        \n",
    "        acc_train = accuracy_score(data[\"train_label\"].cpu(),self.pred_train.squeeze(0).cpu())\n",
    "        self.list_acc_train.append(acc_train)\n",
    "    \n",
    "    def predict(self,input_data) :\n",
    "        input_data = input_data\n",
    "        if type(input_data) == np.ndarray :\n",
    "            None\n",
    "        elif type(input_data) == torch.Tensor :\n",
    "            input_data = input_data.cpu().numpy()\n",
    "        else :\n",
    "            return -1\n",
    "        \n",
    "        input_with_bias = np.ones((input_data.shape[0]+1, input_data.shape[1])) # add bia\n",
    "        input_with_bias[1:, :] = input_data\n",
    "        input_with_bias = torch.DoubleTensor(input_with_bias).to(device)\n",
    "        list_y = []\n",
    "        list_a = []\n",
    "        list_a_bias = [input_with_bias]\n",
    "        \n",
    "        for idx, th in enumerate(self.list_theta) :\n",
    "            y_tmp = torch.mm(th,list_a_bias[-1])\n",
    "            list_y.append(y_tmp)\n",
    "            a_tmp = 1 / (1 + torch.exp(-y_tmp))\n",
    "            list_a.append(a_tmp)\n",
    "            a_bias_tmp = torch.ones((a_tmp.shape[0] + 1, a_tmp.shape[1]), dtype=torch.double).to(device)\n",
    "            a_bias_tmp[1:, :] = a_tmp\n",
    "            list_a_bias.append(a_bias_tmp)\n",
    "\n",
    "        h = list_a[-1]\n",
    "        \n",
    "        pred = h >= 0.5\n",
    "        if pred.shape[0] == 1 :\n",
    "            pred = pred.squeeze(0)\n",
    "        \n",
    "        return pred.cpu()\n",
    "    \n",
    "    # Forward propagation in test data\n",
    "    def forward_propagation_test(self) :\n",
    "        \n",
    "        self.list_y = []\n",
    "        self.list_a = []\n",
    "        self.list_a_bias = [data[\"test_input_with_bias\"]]\n",
    "        for idx, th in enumerate(self.list_theta) :\n",
    "           \n",
    "            y_tmp = torch.mm(th,self.list_a_bias[-1])\n",
    "            self.list_y.append(y_tmp)\n",
    "            a_tmp = 1 / (1 + torch.exp(-y_tmp))\n",
    "            self.list_a.append(a_tmp)\n",
    "            a_bias_tmp = torch.ones((a_tmp.shape[0] + 1, a_tmp.shape[1]), dtype=torch.double).to(device)\n",
    "            a_bias_tmp[1:, :] = a_tmp\n",
    "            self.list_a_bias.append(a_bias_tmp)\n",
    "        self.list_a_bias.pop()\n",
    "        \n",
    "        h = self.list_a[-1]\n",
    "        \n",
    "        # Get Loss value with L2 regulazation\n",
    "        loss_test = torch.sum(-data[\"test_label_vec\"] * (torch.log(h)) - (1 - data[\"test_label_vec\"])* torch.log(1 - h)) / len(h.T) + self.weight_decay*0.5*self.get_mean_theta_square(self.list_theta)\n",
    "        self.list_loss_test.append(loss_test)\n",
    "\n",
    "\n",
    "        # Calculate Acc\n",
    "    \n",
    "        self.pred_test = h >= 0.5\n",
    "        self.list_pred_test.append(self.pred_test)\n",
    "        acc_test = accuracy_score(data[\"test_label\"].cpu(),self.pred_test.squeeze(0).cpu())\n",
    "        self.list_acc_test.append(acc_test)\n",
    "        \n",
    "    def set_gradient_decent (self) :\n",
    "         # Back propagation\n",
    "        self.list_dL = []\n",
    "        self.list_grad = []\n",
    "        \n",
    "        self.list_dL.append(self.list_a[-1]-train_label_vec)\n",
    "        grad = torch.mm(self.list_dL[-1],self.list_a_bias[-1].T) + self.weight_decay*0.5*self.list_theta[-1]/self.th_num\n",
    "        \n",
    "        self.list_grad.append(torch.mm(self.list_dL[-1],self.list_a_bias[-1].T))\n",
    "        idx = 0\n",
    "        # Calculate gradient decent in order from back-end\n",
    "        for i in range(0,self.num_hidden_layer) :\n",
    "            idx += 1\n",
    "            dL_dy = torch.mm(self.list_theta[-idx].T,self.list_dL[-1]) * sig_grad(self.list_a_bias[-idx])\n",
    "            dL_dy = dL_dy[1:, :]\n",
    "            self.list_dL.append(dL_dy)\n",
    "           \n",
    "            # Get gradient decent value Applying L2 Regulazation \n",
    "            grad = torch.mm(dL_dy, self.list_a_bias[-(idx+1)].T)\n",
    "            grad_2 = self.weight_decay*self.list_theta[-(idx+1)]#/self.th_num\n",
    "            grad = grad + grad_2\n",
    "            self.list_grad.append(grad)\n",
    "        self.list_grad.reverse()\n",
    "        \n",
    "        # Update weights \n",
    "    def update_weights(self) :\n",
    "        for th, grad in zip(self.list_theta,self.list_grad) :\n",
    "            th -= self.lr * (grad)\n",
    " \n",
    "    def show_loss_curve(self) :\n",
    "        plt.title(\"Loss curve\")\n",
    "        plot_1, = plt.plot(self.result_train[\"epoch\"],self.result_train[\"loss\"], color='b',linewidth=2,alpha=0.8)\n",
    "        plot_2, = plt.plot(self.result_test[\"epoch\"],self.result_test[\"loss\"], color='r',linewidth=2,alpha=0.8)\n",
    "        plt.legend([plot_1,plot_2],[\"Training\",\"Testing\"])\n",
    "\n",
    "    def show_acc_curve(self) :\n",
    "        plt.title(\"Accuracy curve\")\n",
    "        plot_1, = plt.plot(self.result_train[\"epoch\"],self.result_train[\"acc\"], color='b',linewidth=2,alpha=0.8)\n",
    "        plot_2, = plt.plot(self.result_test[\"epoch\"],self.result_test[\"acc\"], color='r',linewidth=2,alpha=0.8)\n",
    "        plt.legend([plot_1,plot_2],[\"Training\",\"Testing\"])\n",
    "\n",
    "    def show_final_acc(self) :\n",
    "        print(\"Final Training Acc : {:.3f}%\\nFinal Testing Acc : {:.3f}%\".format(self.result_train[\"acc\"][-1]*100,self.result_test[\"acc\"][-1]*100))\n",
    "\n",
    "    def check_top_acc(self) :\n",
    "        if (self.list_acc_test[-1]>0.82) :\n",
    "            if (self.list_acc_test[-1] > self.top_acc) :\n",
    "                self.top_acc = self.list_acc_test[-1]\n",
    "                self.top_acc_epoch = self.list_epoch[-1]\n",
    "                #print(\"epoch : {}, Acc reach the top : {}\".format(self.list_epoch[-1],self.top_acc))\n",
    "    def show_top_acc(self) :\n",
    "        print(\"{}, epoch : {}\".format(self.top_acc,self.top_acc_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Feature size :  2500\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5900\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.027%\n",
      "0.8402662229617305, epoch : 5688\n",
      "##################################################\n",
      "Best classifier is updated.\n",
      "Feature : 2500, Acc : 0.8402662229617305\n",
      "##################################################\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 8006\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.527%\n",
      "0.8402662229617305, epoch : 6165\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6343\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.527%\n",
      "0.8386023294509152, epoch : 5537\n",
      "**************************************************\n",
      "Feature size :  3000\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6507\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.359%\n",
      "0.8469217970049917, epoch : 4874\n",
      "####################################################################################################\n",
      "Best classifier is updated.\n",
      "Feature : 3000, Acc : 0.8469217970049917\n",
      "####################################################################################################\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6852\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.361%\n",
      "0.8336106489184693, epoch : 6648\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6622\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.860%\n",
      "0.8452579034941764, epoch : 5666\n",
      "**************************************************\n",
      "Feature size :  3500\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6627\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.359%\n",
      "0.8452579034941764, epoch : 6302\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6706\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.193%\n",
      "0.8452579034941764, epoch : 5626\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6891\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.193%\n",
      "0.8469217970049917, epoch : 5578\n",
      "**************************************************\n",
      "Feature size :  4000\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 9597\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.526%\n",
      "0.8602329450915142, epoch : 8397\n",
      "####################################################################################################\n",
      "Best classifier is updated.\n",
      "Feature : 4000, Acc : 0.8602329450915142\n",
      "####################################################################################################\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6401\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.860%\n",
      "0.8386023294509152, epoch : 6379\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6766\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.361%\n",
      "0.8502495840266223, epoch : 5649\n",
      "**************************************************\n",
      "Feature size :  4500\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6372\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.193%\n",
      "0.8419301164725458, epoch : 5964\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7037\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.359%\n",
      "0.8535773710482529, epoch : 5585\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 4732\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.361%\n",
      "0.8336106489184693, epoch : 4704\n",
      "**************************************************\n",
      "Feature size :  5000\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 4831\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.694%\n",
      "0.8386023294509152, epoch : 4680\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7138\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.027%\n",
      "0.8419301164725458, epoch : 6126\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6691\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.860%\n",
      "0.8502495840266223, epoch : 5748\n",
      "**************************************************\n",
      "Feature size :  5500\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7066\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.692%\n",
      "0.848585690515807, epoch : 6557\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6692\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.027%\n",
      "0.8419301164725458, epoch : 6641\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7459\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.860%\n",
      "0.8419301164725458, epoch : 6803\n",
      "**************************************************\n",
      "Feature size :  6000\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7106\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 85.025%\n",
      "0.8535773710482529, epoch : 4489\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7196\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.193%\n",
      "0.848585690515807, epoch : 6582\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7106\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 85.524%\n",
      "0.8585690515806988, epoch : 6561\n",
      "**************************************************\n",
      "Feature size :  6500\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6932\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.193%\n",
      "0.8469217970049917, epoch : 6540\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7205\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.359%\n",
      "0.8469217970049917, epoch : 6037\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 4943\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.860%\n",
      "0.8419301164725458, epoch : 4131\n",
      "**************************************************\n",
      "Feature size :  7000\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7328\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.359%\n",
      "0.8452579034941764, epoch : 6223\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5200\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.193%\n",
      "0.8452579034941764, epoch : 4696\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5289\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.526%\n",
      "0.8519134775374376, epoch : 4344\n",
      "**************************************************\n",
      "Feature size :  7500\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5304\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.359%\n",
      "0.8435940099833611, epoch : 4302\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7548\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.193%\n",
      "0.8552412645590682, epoch : 6642\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6747\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.692%\n",
      "0.8502495840266223, epoch : 6239\n",
      "**************************************************\n",
      "Feature size :  8000\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7077\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 85.191%\n",
      "0.8552412645590682, epoch : 6930\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7350\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 85.025%\n",
      "0.8552412645590682, epoch : 6331\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5264\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 82.529%\n",
      "0.8302828618968386, epoch : 4290\n",
      "**************************************************\n",
      "Feature size :  8500\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5502\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.527%\n",
      "0.8369384359400999, epoch : 4531\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5408\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 85.691%\n",
      "0.8569051580698835, epoch : 4933\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7364\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 85.358%\n",
      "0.8652246256239601, epoch : 5671\n",
      "####################################################################################################\n",
      "Best classifier is updated.\n",
      "Feature : 8500, Acc : 0.8652246256239601\n",
      "####################################################################################################\n",
      "**************************************************\n",
      "Feature size :  9000\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6938\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.027%\n",
      "0.8452579034941764, epoch : 6500\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5394\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.027%\n",
      "0.8402662229617305, epoch : 5348\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 4957\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.027%\n",
      "0.8402662229617305, epoch : 4865\n",
      "**************************************************\n",
      "Feature size :  9500\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7203\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 85.025%\n",
      "0.8535773710482529, epoch : 6152\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5132\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.361%\n",
      "0.8336106489184693, epoch : 4271\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5315\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.526%\n",
      "0.8452579034941764, epoch : 4946\n",
      "**************************************************\n",
      "Feature size :  10000\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 4700\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 82.696%\n",
      "0.8302828618968386, epoch : 3994\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5191\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.860%\n",
      "0.8386023294509152, epoch : 5173\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5195\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.361%\n",
      "0.8386023294509152, epoch : 4773\n",
      "**************************************************\n",
      "Feature size :  10500\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5431\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.028%\n",
      "0.8386023294509152, epoch : 4775\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7646\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.193%\n",
      "0.8435940099833611, epoch : 7322\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7467\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.526%\n",
      "0.8502495840266223, epoch : 6267\n",
      "**************************************************\n",
      "Feature size :  11000\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7335\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.692%\n",
      "0.848585690515807, epoch : 6989\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 4964\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.692%\n",
      "0.848585690515807, epoch : 4327\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7265\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.860%\n",
      "0.8419301164725458, epoch : 6712\n",
      "**************************************************\n",
      "Feature size :  11500\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5097\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 82.696%\n",
      "0.826955074875208, epoch : 5071\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 8113\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 85.191%\n",
      "0.8535773710482529, epoch : 6768\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7098\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.859%\n",
      "0.8519134775374376, epoch : 6877\n",
      "**************************************************\n",
      "Feature size :  12000\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7246\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.694%\n",
      "0.8502495840266223, epoch : 6831\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 6989\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.193%\n",
      "0.8452579034941764, epoch : 5850\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7216\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 85.524%\n",
      "0.8618968386023295, epoch : 6302\n",
      "**************************************************\n",
      "Feature size :  12500\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5007\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 82.696%\n",
      "0.826955074875208, epoch : 4884\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5136\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.527%\n",
      "0.8352745424292846, epoch : 4525\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5366\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.694%\n",
      "0.848585690515807, epoch : 4604\n",
      "**************************************************\n",
      "Feature size :  12622\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7187\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 85.358%\n",
      "0.8552412645590682, epoch : 6861\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5427\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.359%\n",
      "0.8435940099833611, epoch : 4484\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5363\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.195%\n",
      "0.831946755407654, epoch : 5197\n",
      "**************************************************\n",
      "Feature size :  12622\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7616\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.193%\n",
      "0.8435940099833611, epoch : 7319\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5420\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.193%\n",
      "0.8419301164725458, epoch : 5344\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5018\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.359%\n",
      "0.8452579034941764, epoch : 4561\n",
      "**************************************************\n",
      "Feature size :  12622\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5120\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 82.529%\n",
      "0.8286189683860233, epoch : 5033\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5283\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 82.696%\n",
      "0.8286189683860233, epoch : 4372\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5058\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.193%\n",
      "0.8419301164725458, epoch : 5057\n",
      "**************************************************\n",
      "Feature size :  12622\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5305\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 85.191%\n",
      "0.8535773710482529, epoch : 4383\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5222\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.027%\n",
      "0.8419301164725458, epoch : 4471\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5463\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.193%\n",
      "0.8435940099833611, epoch : 4913\n",
      "**************************************************\n",
      "Feature size :  12622\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5153\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 85.857%\n",
      "0.8585690515806988, epoch : 5153\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5467\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.860%\n",
      "0.8402662229617305, epoch : 5046\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 4987\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.195%\n",
      "0.8336106489184693, epoch : 4568\n",
      "**************************************************\n",
      "Feature size :  12622\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5049\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.361%\n",
      "0.8352745424292846, epoch : 5042\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5204\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.860%\n",
      "0.8435940099833611, epoch : 4738\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5560\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.692%\n",
      "0.8502495840266223, epoch : 4931\n",
      "**************************************************\n",
      "Feature size :  12622\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5326\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.361%\n",
      "0.8369384359400999, epoch : 4850\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5508\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.860%\n",
      "0.8386023294509152, epoch : 5500\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7518\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.526%\n",
      "0.8585690515806988, epoch : 6512\n",
      "**************************************************\n",
      "Feature size :  12622\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7244\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.526%\n",
      "0.8535773710482529, epoch : 6150\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7558\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.860%\n",
      "0.848585690515807, epoch : 6691\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5077\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.361%\n",
      "0.8369384359400999, epoch : 4397\n",
      "**************************************************\n",
      "Feature size :  12622\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5183\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.027%\n",
      "0.8402662229617305, epoch : 5134\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5056\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.527%\n",
      "0.8386023294509152, epoch : 4783\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7489\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.359%\n",
      "0.848585690515807, epoch : 7142\n",
      "**************************************************\n",
      "Feature size :  12622\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5416\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.694%\n",
      "0.8386023294509152, epoch : 4706\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7956\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.359%\n",
      "0.8452579034941764, epoch : 7804\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 4984\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.527%\n",
      "0.8386023294509152, epoch : 4757\n",
      "**************************************************\n",
      "Feature size :  12622\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5040\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.195%\n",
      "0.831946755407654, epoch : 4976\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5058\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.027%\n",
      "0.8452579034941764, epoch : 4830\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5136\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.860%\n",
      "0.8469217970049917, epoch : 4372\n",
      "**************************************************\n",
      "Feature size :  12622\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5392\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.027%\n",
      "0.8402662229617305, epoch : 5379\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 7082\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.694%\n",
      "0.8419301164725458, epoch : 6266\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5305\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 82.696%\n",
      "0.8302828618968386, epoch : 4627\n",
      "**************************************************\n",
      "Feature size :  12622\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5302\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.195%\n",
      "0.8435940099833611, epoch : 4822\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5359\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.860%\n",
      "0.8435940099833611, epoch : 4537\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5284\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 83.361%\n",
      "0.8386023294509152, epoch : 4495\n",
      "**************************************************\n",
      "Feature size :  12622\n",
      "**************************************************\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5539\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 82.696%\n",
      "0.831946755407654, epoch : 4496\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 4995\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.193%\n",
      "0.8469217970049917, epoch : 4196\n",
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Loss is converged. epoch 5594\n",
      "Training Process Ended\n",
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.692%\n",
      "0.8502495840266223, epoch : 5330\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_classifier = None\n",
    "best_acc = None\n",
    "best_acc_epoch = None\n",
    "for i in range(5,40) :\n",
    "    preprocess_data(i*500,5,0.5)\n",
    "    print(\"*\"*50)\n",
    "    print(\"Feature size : \",data[\"train_input\"].shape[0])\n",
    "    print(\"*\"*50)\n",
    "\n",
    "\n",
    "    for j in range(0,3) :\n",
    "        classifier = train_classifier(data,layer_info=[20,12,1],lr= 1e-3,loss_conv = 1e-7,weight_decay=4e-1,monitoring_epoch=0)\n",
    "        classifier.show_final_acc()\n",
    "        classifier.show_top_acc()\n",
    "        if not best_classifier :\n",
    "            best_classifier = classifier\n",
    "            best_acc = classifier.top_acc\n",
    "            best_acc_epoch = classifier.top_acc_epoch\n",
    "            print(\"#\"*50)\n",
    "            print(\"Best classifier is updated.\\nFeature : {}, Acc : {}\".format(data[\"train_input\"].shape[0],best_acc,best_acc_epoch))\n",
    "            print(\"#\"*50)\n",
    "            continue\n",
    "\n",
    "        if best_classifier.top_acc < classifier.top_acc :\n",
    "            best_classifier = classifier\n",
    "            best_acc = classifier.top_acc\n",
    "            best_acc_epoch = classifier.top_acc_epoch\n",
    "            print(\"#\"*100)\n",
    "            print(\"Best classifier is updated.\\nFeature : {}, Acc : {}\".format(data[\"train_input\"].shape[0],best_acc,best_acc_epoch))\n",
    "            print(\"#\"*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier.show_loss_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier.show_acc_curve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 84.692%\n"
     ]
    }
   ],
   "source": [
    "classifier.show_final_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Acc : 100.000%\n",
      "Final Testing Acc : 85.358%\n",
      "0.8652246256239601, epoch : 5671\n"
     ]
    }
   ],
   "source": [
    "best_classifier.show_final_acc()\n",
    "best_classifier.show_top_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_classifier.show_loss_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_classifier.show_acc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [20, 12, 1]\n",
      "Train Acc : 0.772, Loss : 0.54084504 | epoch : 1000, time : 00:00:12\n",
      "Test  Acc : 0.656, Loss : 0.75410921\n",
      "Train Acc : 0.999, Loss : 0.05133533 | epoch : 2000, time : 00:00:24\n",
      "Test  Acc : 0.757, Loss : 0.75648905\n",
      "Train Acc : 1.000, Loss : 0.02654948 | epoch : 3000, time : 00:00:37\n",
      "Test  Acc : 0.772, Loss : 0.61596463\n",
      "Train Acc : 0.502, Loss : 0.69254383 | epoch : 4000, time : 00:00:50\n",
      "Test  Acc : 0.511, Loss : 0.94616735\n",
      "Train Acc : 1.000, Loss : 0.01042069 | epoch : 5000, time : 00:01:02\n",
      "Test  Acc : 0.839, Loss : 0.41922890\n",
      "Train Acc : 1.000, Loss : 0.00955608 | epoch : 6000, time : 00:01:15\n",
      "Test  Acc : 0.844, Loss : 0.38128214\n",
      "Train Acc : 1.000, Loss : 0.00877260 | epoch : 7000, time : 00:01:27\n",
      "Test  Acc : 0.849, Loss : 0.39298613\n",
      "Loss is converged. epoch 7419\n",
      "Training Process Ended\n"
     ]
    }
   ],
   "source": [
    "preprocess_data(8500,5,0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- ML START --------------------\n",
      "lr : 0.001, weight_decay : 0.4, loss_conv : 1e-07, thetas : [50, 12, 1]\n",
      "Train Acc : 0.758, Loss : 0.55156107 | epoch : 1000, time : 00:00:16\n",
      "Test  Acc : 0.619, Loss : 0.83134306\n",
      "Train Acc : 0.999, Loss : 0.05066346 | epoch : 2000, time : 00:00:33\n",
      "Test  Acc : 0.770, Loss : 0.79730464\n"
     ]
    }
   ],
   "source": [
    "classifier = train_classifier(data,layer_info=[50,12,1],lr= 1e-3,loss_conv = 1e-7,weight_decay=4e-1,monitoring_epoch=1000)\n",
    "classifier.show_top_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-61030fe20695>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4e-1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonitoring_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclassifier2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_final_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "classifier2 = train_classifier(layer_info=[20,12,1],lr= 1e-3,loss_conv = 1e-10,weight_decay=4e-1,monitoring_epoch=1000)\n",
    "classifier2.show_final_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_shape = [1]\n",
    "\n",
    "for i in range(0,20) :\n",
    "    for j in range(0,20) :\n",
    "        layer_shape.append((i+1)*3)\n",
    "        layer_shape.append((j+1)*5)\n",
    "        layer_shape.reverse()\n",
    "        classifier = train_classifier(layer_info=layer_shape,lr= 1e-3,loss_conv = 1e-8,weight_decay=4e-1,monitoring_epoch=0)\n",
    "        classifier.show_final_acc()\n",
    "        layer_shape.reverse()\n",
    "        layer_shape.pop()\n",
    "        layer_shape.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_shape = [1]\n",
    "\n",
    "for i in range(0,10) :\n",
    "    layer_shape.append((i+1)*10)\n",
    "    layer_shape.reverse()\n",
    "    classifier = train_classifier(layer_info=layer_shape,lr= 1e-3,loss_conv = 1e-5,weight_decay=4e-1,monitoring_epoch=0)\n",
    "    classifier.show_final_acc()\n",
    "    layer_shape.reverse()\n",
    "    layer_shape.pop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_label.cpu()\n",
    "y_pred_train = ml.list_pred_train[-1].squeeze(0).cpu()\n",
    "y_test = test_label.cpu()\n",
    "y_pred_test = ml.list_pred_test[-1].squeeze(0).cpu()\n",
    "print(y_train.shape,y_pred_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = classifier.predict(test_image)\n",
    "y_pred_train = classifier.predict(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_label.cpu()\n",
    "y_train = train_label.cpu()\n",
    "print(confusion_matrix(y_train,y_pred_train))\n",
    "print(classification_report(y_train,y_pred_train))\n",
    "print(accuracy_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))\n",
    "print(accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_train,y_pred_train))\n",
    "print(classification_report(y_train,y_pred_train))\n",
    "print(accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))\n",
    "print(accuracy_score(y_test, y_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_loss_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the accuracy curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_acc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the accuracy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_final_acc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the classification example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctly classified testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_correct_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misclassified testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.show_incorrect_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
